{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Run the following pip install to access the streamlit library in google colab"
      ],
      "metadata": {
        "id": "G4TZmraqDc9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit -q"
      ],
      "metadata": {
        "id": "j7PxAQ5FXoL9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main function code is as follows:"
      ],
      "metadata": {
        "id": "RxqSnslbDmMj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29dE7Bb-XaBN",
        "outputId": "4860530e-bd50-472e-b197-8a3e1a850e98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import IPython.display as display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (12, 12)\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import time\n",
        "import functools\n",
        "import io\n",
        "import requests\n",
        "from tensorflow.keras.preprocessing.image import save_img\n",
        "import streamlit as st\n",
        "import os.path\n",
        "import time\n",
        "\n",
        "class CFG:\n",
        "    debug=False\n",
        "    epochs=10 if (debug==False) else 1\n",
        "    steps_per_epoch=100 if (debug==False) else 10\n",
        "    contentimg=\"contentimage.jpg\"\n",
        "    styleimg=\"styleimage.jpg\"\n",
        "    finalimg=\"Generatedimage.jpg\"\n",
        "\n",
        "\n",
        "def TrainModel(content_path,style_path):\n",
        "\n",
        "    class Layers:\n",
        "      StyleLayers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "      ContentLayers = ['block5_conv2']\n",
        "      NoContentLayers = len(ContentLayers)\n",
        "      NoStyleLayers = len(StyleLayers)\n",
        "\n",
        "    def tensor_to_image(tensor):\n",
        "        tensor = tensor*255\n",
        "        tensor = np.array(tensor, dtype=np.uint8)\n",
        "        if np.ndim(tensor)>3:\n",
        "            assert tensor.shape[0] == 1\n",
        "            tensor = tensor[0]\n",
        "        return PIL.Image.fromarray(tensor)\n",
        "\n",
        "\n",
        "    def load_img(path_to_img):\n",
        "        max_dim = 512\n",
        "        img = tf.io.read_file(path_to_img)\n",
        "        img = tf.image.decode_image(img, channels=3)\n",
        "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "\n",
        "        shape = tf.cast(tf.shape(img)[:-1], tf.float32)\n",
        "        long_dim = max(shape)\n",
        "        scale = max_dim / long_dim\n",
        "\n",
        "        new_shape = tf.cast(shape * scale, tf.int32)\n",
        "\n",
        "        img = tf.image.resize(img, new_shape)\n",
        "        img = img[tf.newaxis, :]\n",
        "        return img\n",
        "\n",
        "    content_path = content_path\n",
        "    style_path = style_path\n",
        "    content_image = load_img(content_path)\n",
        "    style_image = load_img(style_path)\n",
        "\n",
        "    def vgg_layers(layers):\n",
        "        vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
        "        vgg.trainable = False\n",
        "\n",
        "        outputs = [vgg.get_layer(layer).output for layer in layers]\n",
        "\n",
        "        model = tf.keras.Model([vgg.input], outputs)\n",
        "        return model\n",
        "\n",
        "    def GramMatrix(IniTensor):\n",
        "        result = tf.linalg.einsum('bijc,bijd->bcd', IniTensor, IniTensor)\n",
        "        shape = tf.shape(IniTensor)\n",
        "        Total = tf.cast(shape[1]*shape[2], tf.float32)\n",
        "        return (result/(Total))\n",
        "\n",
        "\n",
        "    class StyleContentModel(tf.keras.models.Model):\n",
        "        def __init__(self, style_layers, content_layers):\n",
        "            super(StyleContentModel, self).__init__()\n",
        "            self.vgg = vgg_layers(style_layers + content_layers)\n",
        "            self.style_layers = style_layers\n",
        "            self.content_layers = content_layers\n",
        "            self.num_style_layers = len(style_layers)\n",
        "            self.vgg.trainable = False\n",
        "\n",
        "        def call(self, inputs):\n",
        "            inputs = 255.0*inputs\n",
        "            preprocessed = tf.keras.applications.vgg19.preprocess_input(inputs)\n",
        "            outputs = self.vgg(preprocessed)\n",
        "            style_outputs, content_outputs = (outputs[:self.num_style_layers], outputs[self.num_style_layers:])\n",
        "\n",
        "            style_outputs = [GramMatrix(style_output) for style_output in style_outputs]\n",
        "\n",
        "            content_dict = {content_name: value for content_name, value in zip(self.content_layers, content_outputs)}\n",
        "\n",
        "            style_dict = {style_name: value for style_name, value in zip(self.style_layers, style_outputs)}\n",
        "\n",
        "            return {'content': content_dict, 'style': style_dict}\n",
        "\n",
        "    extractor = StyleContentModel(Layers.StyleLayers, Layers.ContentLayers)\n",
        "    style_targets = extractor(style_image)['style']\n",
        "    content_targets = extractor(content_image)['content']\n",
        "    image = tf.Variable(content_image)\n",
        "\n",
        "    def getfloat(image):\n",
        "      return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n",
        "\n",
        "    optimiser = tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)\n",
        "\n",
        "    style_weight=1e-2\n",
        "    content_weight=1e4\n",
        "    total_variation_weight=30\n",
        "\n",
        "    def Loss(outputs):\n",
        "        style_outputs = outputs['style']\n",
        "        content_outputs = outputs['content']\n",
        "        style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2) for name in style_outputs.keys()])\n",
        "        style_loss *= style_weight / Layers.NoStyleLayers\n",
        "\n",
        "        content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**2) for name in content_outputs.keys()])\n",
        "        content_loss *= content_weight / Layers.NoContentLayers\n",
        "        return style_loss+content_loss\n",
        "\n",
        "    @tf.function()\n",
        "    def train_step(image):\n",
        "        with tf.GradientTape() as tape:\n",
        "            outputs = extractor(image)\n",
        "            loss = Loss(outputs)\n",
        "\n",
        "        grad = tape.gradient(loss, image)\n",
        "        optimiser.apply_gradients([(grad, image)])\n",
        "        image.assign(getfloat(image))\n",
        "\n",
        "    n = CFG.epochs\n",
        "    m = CFG.steps_per_epoch\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            train_step(image)\n",
        "    save_img('Generatedimage.jpg', tensor_to_image(image))\n",
        "\n",
        "def save_uploadedfile(uploadedfile,name):\n",
        "     with open(os.path.join(\".\",name),\"wb\") as f:\n",
        "         f.write(uploadedfile.getbuffer())\n",
        "     return st.success(\"File Uploaded\")\n",
        "\n",
        "st.write(\"# Neural Style Transfer\")\n",
        "st.write(\"#### make sure the file is in a readable format\")\n",
        "\n",
        "contentImage = st.file_uploader(\"Upload the Image\")\n",
        "styleImage = st.file_uploader(\"Upload the Style\")\n",
        "if contentImage is not None and styleImage is not None:\n",
        "    image = PIL.Image.open(contentImage)\n",
        "    design = PIL.Image.open(styleImage)\n",
        "    st.image(image, caption='Content Image')\n",
        "    st.image(design, caption='Style Image')\n",
        "    save_uploadedfile(contentImage,\"contentimage.jpg\")\n",
        "    save_uploadedfile(styleImage,\"styleimage.jpg\")\n",
        "    st.button('Generate Image', on_click=TrainModel,args=(CFG.contentimg,CFG.styleimg))\n",
        "\n",
        "while True:\n",
        "        if os.path.isfile(CFG.finalimg) :\n",
        "            st.success(\"Result: \")\n",
        "            FinalImage=PIL.Image.open(CFG.finalimg)\n",
        "            st.image(FinalImage, caption='Generated Image')\n",
        "            break\n",
        "        time.sleep(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code to generate the IP used as a password for tunnel website"
      ],
      "metadata": {
        "id": "cf1zb7RoDp0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiJI3aBtXqaO",
        "outputId": "d2c71b26-2f31-41be-f494-fd2a99d9ea89"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.34.57.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the following code to generate the website, accessed with the link provided"
      ],
      "metadata": {
        "id": "YCwWBhj1Dwp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqnRm_npXsjQ",
        "outputId": "90b1afc4-2be5-48be-ca37-6ca46ac496e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.34.57.13:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.06s\n",
            "your url is: https://loud-schools-dance.loca.lt\n",
            "2024-06-20 17:01:43.500512: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-20 17:01:43.500565: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-20 17:01:43.501989: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-20 17:01:43.510081: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-20 17:01:44.632913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-06-20 17:04:02.441349: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-06-20 17:04:02.494176: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-06-20 17:04:02.494508: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-06-20 17:04:02.496096: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-06-20 17:04:02.496402: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-06-20 17:04:02.496614: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-06-20 17:04:02.593171: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-06-20 17:04:02.593512: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-06-20 17:04:02.593670: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2024-06-20 17:04:02.593765: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-06-20 17:04:02.593923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "2024-06-20 17:04:03.276199: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
            "2024-06-20 17:04:09.468767: I external/local_xla/xla/service/service.cc:168] XLA service 0x56419bc82880 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2024-06-20 17:04:09.468816: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2024-06-20 17:04:09.488799: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1718903049.663267   17147 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}